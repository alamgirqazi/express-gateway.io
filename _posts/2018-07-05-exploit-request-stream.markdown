---
title: Exploiting the new requestStream proprety with Express Gateway
date: 2018-07-25 07:04:00 Z
categories:
- technology
tags:
- How to build microservices
- Service Mesh
- What is a Service Mesh?
- Why is a service mesh important?
- Monolith architecture and service mesh
- service to service communication
- What is an API Gateway
layout: post
author: Vincenzo Chianese
---

We just released [Express Gateway 1.10][eg-1-10]. In addition to fixing important bugs, the latest release contains some interesting new features. We've included a deeper looks into the new [requestStream][egContext] property which has been added to the [plugin framework][plugin-framework].

<!--excerpt-->

## Navigating The New requestStream Property And egContext

When a request is processed by Express Gateway, this request is enriched with a bag object called [`egContext`][egContext]. This object contains specific information that Express Gateway already knows about your system. This allows you to have more efficient introspection capabilities. For example, every request has the `apiEndpoint` name that triggered the Gateway, as well as the required scopes.

Starting with 1.10, the [egContext][egContext] object also contains a new property called `requestStream`. This property is a [stream](https://nodejs.org/api/stream.html) that will be forwarded to the selected `serviceEndpoint` as the request body instead of the original payload contained in the canonical request. Up next, we'll show you how to put it to use in a easy-to-follow example with code snippets so you can try it out.

## How to parse a JSON or URL encoded request

Most of the times, tampering the user payload is not something we want to do. However; there are some cases where we might want to do that, but in a very controlled and precise way.

In this example, learn more about how to use the new `requestStream` property to parse a JSON or URL encoded request body and restream it back so that's avaiable for other policies for processing.

## The problem

Usually, the request body is simply streamed as a byte array from the source client to the destination endpoint to minimize the Gateway's memory usage. This method also improves performance.

Let's say we want to save the request body for logging or introspection purposes. In this case, we need to store it entirely in memory before starting to operate on it.

Express.js already offers two body parser implementations that accomplish this.  for us. The code for a hypothetical plugin that implements this policy could be something like:

```javascript
const jsonParser = require('express').json();
const urlEncodedParser = require('express').urlEncoded({ extended: true });

const policy = actionParams => (req, res, next) =>
  jsonParser(req, res, () => urlEncoded(req, res, next));

```

Then install such policy in any of the pipelines and, _in theory_, the subsequent policies should have access to the `req.body` property.

```yml
    policies:
      - body-parser:
      - log:
        - condition:
            name: expression
            expression: "req.body.start > 5"
          action:
            message: '"Current user is approaching limits"'
      - proxy:
          - action:
              serviceEndpoint: backend

```


In this case, we're using the parsed body to test a [conditions][conditions] that'll trigger a log policy, if the condition holds true.

Now, we can try to shoot a request to the Express Gateway and see what happens:

```shell
curl -X POST -h "Content-Type: application/json" -d '{"limit":4, "name":"Clark"}' http://localhost:8080
…
…
…
Request Timeout
```

The request doesn't go through and we never receive a response back. Why's that happening?

When the `bodyParser` policy is parsing the body, it's basically reading through the request stream and, once it's over, it parses the body using the appropriate function.

While doing this operation, it's consuming the request stream. Once it's over, the content is kind of lost and cannot be rewrapped.

We're sending to the target `serviceEndpoint` a `Content-Length` header that's claiming a certain amount of bytes are going to be sent — but we are not actually sending it. That's why it results in a timeout.

Fortunately for us, request streams can be piped — which means that fundamentally it's content can be streamed to multiple destinations at the same time.

In our case, we'll pipe the original stream into an in-memory copy stream. Then we'll send it out using the `requestStream` property.

```javascript
const { PassThrough } = require("stream");
const jsonParser = require("express").json();
const urlEncodedParser = require("express").urlEncoded({ extended: true });

const policy = actionParams => {
  return (req, res, next) => {
    req.egContext.requestStream = new PassThrough();
    req.pipe(req.egContext.requestStream);

    return jsonParser(req, res, () => urlEncoded(req, res, next));
  };
};
```

The flow here is:

- The request comes in the Gateway
- The body parsers (`json` and `urlencoded`) start to read the stream gradually until it reaches the end
- We piped the request stream to the `requestStream` property so every read gets held in the [PassThrough][ps] stream
- In this case, we created a copy of the original requaest so the content is the same.
- Request goes out
- We receive a response back

## Conclusions

We shared how the new `requestStream` property in Express Gateway 1.10 can be used to restream content that has been parsed for our own use. There are so many use cases for this brand new property. Stay tuned because we'll explore another interesting use case where the `requestStream` property can be used to implement a body modifier policy with Express Gateway.

[eg-1-10]: https://github.com/ExpressGateway/express-gateway/releases/tag/v1.10.1
[plugin-framework]: https://www.express-gateway.io/docs/plugins/
[egContext]: https://www.express-gateway.io/docs/policies/customization/eg-context/#description
[conditions]: https://www.express-gateway.io/docs/policies/customization/conditions/
[ps]: https://nodejs.org/api/stream.html#stream_class_stream_passthrough
